{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798c257a-5ffa-4b64-8d77-cbf8d3bc9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Cell: Importing Libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For saving images and visualizing the data\n",
    "import shutil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bcd4a3d-c405-40cb-accc-97dcef17c1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4117 tumor images and 1595 no-tumor images.\n"
     ]
    }
   ],
   "source": [
    "# Second Cell: Load Images from Folder\n",
    "# Second Cell: Load and Resize Images from Folder\n",
    "def load_images_from_folder(folder_path, target_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Loads and resizes images from a specified folder.\n",
    "    Returns a numpy array of uniformly sized images.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "        if img is not None:\n",
    "            resized_img = cv2.resize(img, target_size)\n",
    "            images.append(resized_img)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "# Load images from your \"tumor\" and \"no-tumor\" folders\n",
    "tumor_dir = r\"C:\\Users\\anura\\Desktop\\REBIRTHTHENEWHOPE\\Deep-Fake-Detection\\data\\DATA\\Training\\tumor\"  # Update with the correct path\n",
    "no_tumor_dir = r\"C:\\Users\\anura\\Desktop\\REBIRTHTHENEWHOPE\\Deep-Fake-Detection\\data\\DATA\\Training\\notumor\"  # Update with the correct path\n",
    "\n",
    "tumor_images = load_images_from_folder(tumor_dir)\n",
    "no_tumor_images = load_images_from_folder(no_tumor_dir)\n",
    "\n",
    "print(f\"Loaded {len(tumor_images)} tumor images and {len(no_tumor_images)} no-tumor images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fabc83da-f219-4fb7-9708-77aa6bd7500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced: 6380 no-tumor images, 6380 tumor images\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "target_size = 6380  # Desired size per class\n",
    "\n",
    "# Oversampling function\n",
    "def oversample_images(images, target_size):\n",
    "    \"\"\"\n",
    "    Oversample the images by randomly selecting images with replacement.\n",
    "    \"\"\"\n",
    "    current_size = len(images)\n",
    "    if current_size < target_size:\n",
    "        indices = np.random.randint(0, current_size, size=(target_size - current_size))\n",
    "        duplicates = images[indices]\n",
    "        images = np.concatenate((images, duplicates), axis=0)\n",
    "    return images\n",
    "\n",
    "# Undersampling function\n",
    "def undersample_images(images, target_size):\n",
    "    \"\"\"\n",
    "    Undersample the images by randomly selecting a subset without replacement.\n",
    "    \"\"\"\n",
    "    current_size = len(images)\n",
    "    if current_size > target_size:\n",
    "        indices = np.random.choice(current_size, target_size, replace=False)\n",
    "        images = images[indices]\n",
    "    return images\n",
    "\n",
    "# Apply balancing\n",
    "no_tumor_images = oversample_images(no_tumor_images, target_size)\n",
    "tumor_images = oversample_images(tumor_images, target_size)\n",
    "\n",
    "print(f\"Balanced: {len(no_tumor_images)} no-tumor images, {len(tumor_images)} tumor images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a7e792a-87c8-44a4-9763-067bd523cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset saved: No-Tumor images in C:\\Users\\anura\\Desktop\\REBIRTHTHENEWHOPE\\Deep-Fake-Detection\\data\\DATA\\Training\\notumor_1_SAVE, Tumor images in C:\\Users\\anura\\Desktop\\REBIRTHTHENEWHOPE\\Deep-Fake-Detection\\data\\DATA\\Training\\tumor_1_SAVE.\n"
     ]
    }
   ],
   "source": [
    "# Fourth Cell: Save the Balanced Dataset to Disk\n",
    "\n",
    "def save_images(images, save_dir, prefix):\n",
    "    \"\"\"\n",
    "    Save the balanced images to a directory with a specific prefix (e.g., 'no_tumor').\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    for idx, img in enumerate(images):\n",
    "        img_name = f\"{prefix}_{idx}.png\"\n",
    "        img_path = os.path.join(save_dir, img_name)\n",
    "        cv2.imwrite(img_path, img)\n",
    "\n",
    "# Define the directories to save your balanced data\n",
    "save_no_tumor_dir = r\"C:\\Users\\anura\\Desktop\\REBIRTHTHENEWHOPE\\Deep-Fake-Detection\\data\\DATA\\Training\\notumor_1_SAVE\"  # Update with the correct path\n",
    "save_tumor_dir = r\"C:\\Users\\anura\\Desktop\\REBIRTHTHENEWHOPE\\Deep-Fake-Detection\\data\\DATA\\Training\\tumor_1_SAVE\"  # Update with the correct path\n",
    "\n",
    "# Save the images\n",
    "save_images(no_tumor_images, save_no_tumor_dir, \"no_tumor\")\n",
    "save_images(tumor_images, save_tumor_dir, \"tumor\")\n",
    "\n",
    "print(f\"Balanced dataset saved: No-Tumor images in {save_no_tumor_dir}, Tumor images in {save_tumor_dir}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6a675e6-7951-4921-9efa-33b460e1be58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 12760 images\n"
     ]
    }
   ],
   "source": [
    "# Fifth Cell: Prepare Dataset for PyTorch Training (Optional)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TumorDataset(Dataset):\n",
    "    def __init__(self, tumor_images, no_tumor_images):\n",
    "        \"\"\"\n",
    "        Custom Dataset for handling balanced tumor and no-tumor images.\n",
    "        \"\"\"\n",
    "        self.tumor_images = tumor_images\n",
    "        self.no_tumor_images = no_tumor_images\n",
    "        self.labels = [1] * len(tumor_images) + [0] * len(no_tumor_images)  # 1 for tumor, 0 for no-tumor\n",
    "        self.images = np.concatenate([tumor_images, no_tumor_images], axis=0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(image, dtype=torch.float32).unsqueeze(0), label  # Adjust for grayscale or RGB\n",
    "\n",
    "# Create the dataset\n",
    "dataset = TumorDataset(tumor_images, no_tumor_images)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05617057-98b6-483e-b878-c774a14b32d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651326e-2381-4ba0-8a43-c071b33ef034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (BTD)",
   "language": "python",
   "name": "btd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
