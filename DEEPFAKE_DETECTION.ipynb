{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bfed180-b72a-417a-a22a-93f8c2efcd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# 📦 Step 1: Imports and Setup\n",
    "# =======================================\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04858a24-583b-4edc-9049-60cc7e17c33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a70549f-0537-4530-b0f0-0d9b20e10b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class BrainMRIDataset(Dataset):\n",
    "    def __init__(self, root_dir, mode='Training', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Path to 'split_data'\n",
    "            mode (str): 'Training' or 'Testing'\n",
    "            transform: torchvision transforms\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "\n",
    "        # Labels: Real = 0, Fake = 1\n",
    "        class_map = {'Real': 0, 'Fake': 1}\n",
    "\n",
    "        for class_name, label in class_map.items():\n",
    "            folder_path = os.path.join(root_dir, class_name, mode)\n",
    "            for img_file in os.listdir(folder_path):\n",
    "                img_path = os.path.join(folder_path, img_file)\n",
    "                self.data.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f30e7a2-1efd-448c-a3c7-51e63b53b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "root_dir='./data/Dataset/'\n",
    "# Load pre-split datasets from Step 2\n",
    "train_dataset = BrainMRIDataset(root_dir=root_dir , mode='Training', transform=transform)\n",
    "val_dataset = BrainMRIDataset(root_dir=root_dir , mode='Testing', transform=transform)\n",
    "\n",
    "# Step 4: DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79ea8ff6-5227-4dea-b944-6c3f4e9b8429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\.conda\\envs\\btd\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anura\\.conda\\envs\\btd\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# Load pre-trained ResNet-18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)  # Assuming binary classification (Real vs Fake)\n",
    "\n",
    "# Move the model to the appropriate device (GPU or CPU)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "823c30e6-d2d7-41ef-a5d2-e069cc126a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# 🏃 Step 5: Training & Validation Functions\n",
    "# =======================================\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# =======================================\n",
    "# 🏃 Step 5: Training & Validation Functions\n",
    "# =======================================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # You can try a higher lr for faster convergence\n",
    "num_epochs = 10\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs=num_epochs):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"\\nEpoch {epoch+1} - Training Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Validation\n",
    "        acc = evaluate(model, val_loader)\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"✅ Best model saved!\")\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Validating\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"Accuracy:\", acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d29f99-0c29-4fb7-a53d-8148e2989909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████████████| 399/399 [05:27<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 - Training Loss: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3240\n",
      "           1       1.00      1.00      1.00      2552\n",
      "\n",
      "    accuracy                           1.00      5792\n",
      "   macro avg       1.00      1.00      1.00      5792\n",
      "weighted avg       1.00      1.00      1.00      5792\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3240    0]\n",
      " [   0 2552]]\n",
      "Accuracy: 1.0\n",
      "✅ Best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|███████████████████████████████████████████████████████████████████████| 399/399 [04:25<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 - Training Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 91/91 [00:51<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3240\n",
      "           1       1.00      1.00      1.00      2552\n",
      "\n",
      "    accuracy                           1.00      5792\n",
      "   macro avg       1.00      1.00      1.00      5792\n",
      "weighted avg       1.00      1.00      1.00      5792\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3240    0]\n",
      " [   0 2552]]\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|███████████████████████████████████████████████████████████████████████| 399/399 [05:38<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 - Training Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████████████████████████████████████████████████████████████████| 91/91 [01:30<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3240\n",
      "           1       1.00      1.00      1.00      2552\n",
      "\n",
      "    accuracy                           1.00      5792\n",
      "   macro avg       1.00      1.00      1.00      5792\n",
      "weighted avg       1.00      1.00      1.00      5792\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3240    0]\n",
      " [   0 2552]]\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:  13%|█████████▍                                                              | 52/399 [00:58<06:21,  1.10s/it]"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# 🔥 Step 6: Start Training\n",
    "# =======================================\n",
    "train(model, train_loader, val_loader, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73606728-f4b8-4929-b1e7-5caaf4fdff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# 💾 Step 7: Save the Trained Model\n",
    "# =======================================\n",
    "if not os.path.exists('model'):\n",
    "    os.makedirs('model')\n",
    "torch.save(model.state_dict(), \"model/best_resnet_model.pth\")\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f600d-a219-413a-8ceb-1993f02fa616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (BTD)",
   "language": "python",
   "name": "btd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
